{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adcce854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7f4999c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flags</th>\n",
       "      <th>utterance</th>\n",
       "      <th>category</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BM</td>\n",
       "      <td>I have problems with canceling an order</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>cancel_order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BIM</td>\n",
       "      <td>how can I find information about canceling ord...</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>cancel_order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>I need help with canceling the last order</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>cancel_order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BIP</td>\n",
       "      <td>could you help me cancelling the last order I ...</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>cancel_order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>problem with cancelling an order I made</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>cancel_order</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  flags                                          utterance category  \\\n",
       "0    BM            I have problems with canceling an order    ORDER   \n",
       "1   BIM  how can I find information about canceling ord...    ORDER   \n",
       "2     B          I need help with canceling the last order    ORDER   \n",
       "3   BIP  could you help me cancelling the last order I ...    ORDER   \n",
       "4     B            problem with cancelling an order I made    ORDER   \n",
       "\n",
       "         intent  \n",
       "0  cancel_order  \n",
       "1  cancel_order  \n",
       "2  cancel_order  \n",
       "3  cancel_order  \n",
       "4  cancel_order  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"Bitext_Sample_Customer_Service_Training_Dataset.csv\")\n",
    "\n",
    "# Display the first few rows to understand its structure\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce04b8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flags        0\n",
       "utterance    0\n",
       "category     0\n",
       "intent       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a9dfd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_4976\\1120789529.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['cleaned_utterance'] = df['utterance'].str.lower().str.replace('[^\\w\\s]', ' ').str.strip()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>cleaned_utterance</th>\n",
       "      <th>tokenized_utterance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have problems with canceling an order</td>\n",
       "      <td>i have problems with canceling an order</td>\n",
       "      <td>[i, have, problems, with, canceling, an, order]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how can I find information about canceling ord...</td>\n",
       "      <td>how can i find information about canceling orders</td>\n",
       "      <td>[how, can, i, find, information, about, cancel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I need help with canceling the last order</td>\n",
       "      <td>i need help with canceling the last order</td>\n",
       "      <td>[i, need, help, with, canceling, the, last, or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>could you help me cancelling the last order I ...</td>\n",
       "      <td>could you help me cancelling the last order i ...</td>\n",
       "      <td>[could, you, help, me, cancelling, the, last, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>problem with cancelling an order I made</td>\n",
       "      <td>problem with cancelling an order i made</td>\n",
       "      <td>[problem, with, cancelling, an, order, i, made]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           utterance  \\\n",
       "0            I have problems with canceling an order   \n",
       "1  how can I find information about canceling ord...   \n",
       "2          I need help with canceling the last order   \n",
       "3  could you help me cancelling the last order I ...   \n",
       "4            problem with cancelling an order I made   \n",
       "\n",
       "                                   cleaned_utterance  \\\n",
       "0            i have problems with canceling an order   \n",
       "1  how can i find information about canceling orders   \n",
       "2          i need help with canceling the last order   \n",
       "3  could you help me cancelling the last order i ...   \n",
       "4            problem with cancelling an order i made   \n",
       "\n",
       "                                 tokenized_utterance  \n",
       "0    [i, have, problems, with, canceling, an, order]  \n",
       "1  [how, can, i, find, information, about, cancel...  \n",
       "2  [i, need, help, with, canceling, the, last, or...  \n",
       "3  [could, you, help, me, cancelling, the, last, ...  \n",
       "4    [problem, with, cancelling, an, order, i, made]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Basic text cleaning\n",
    "df['cleaned_utterance'] = df['utterance'].str.lower().str.replace('[^\\w\\s]', ' ').str.strip()\n",
    "\n",
    "#Tokenize the text\n",
    "df['tokenized_utterance'] = df['cleaned_utterance'].str.split()\n",
    "\n",
    "#First few rows after cleaning and tokenization\n",
    "df[['utterance', 'cleaned_utterance', 'tokenized_utterance']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a9be462",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((6540, 641), (817, 641), (818, 641))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "\n",
    "#Stopwords removal\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['cleaned_utterance'] = df['cleaned_utterance'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
    "\n",
    "#TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(df['cleaned_utterance']).toarray()\n",
    "\n",
    "#Encode the intent labels\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(df['intent'])\n",
    "\n",
    "#Splitting the data into training (80%), validation (10%), and testing (10%) sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "#Output the shape of the datasets\n",
    "(X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4a32ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        31\n",
      "           1       1.00      0.97      0.98        30\n",
      "           2       0.97      1.00      0.98        30\n",
      "           3       1.00      1.00      1.00        30\n",
      "           4       1.00      1.00      1.00        32\n",
      "           5       1.00      1.00      1.00        30\n",
      "           6       1.00      1.00      1.00        30\n",
      "           7       1.00      1.00      1.00        30\n",
      "           8       1.00      0.97      0.98        30\n",
      "           9       1.00      1.00      1.00        30\n",
      "          10       0.91      0.97      0.94        30\n",
      "          11       1.00      1.00      1.00        30\n",
      "          12       1.00      1.00      1.00        30\n",
      "          13       1.00      1.00      1.00        30\n",
      "          14       1.00      1.00      1.00        30\n",
      "          15       1.00      1.00      1.00        32\n",
      "          16       1.00      1.00      1.00        30\n",
      "          17       1.00      1.00      1.00        30\n",
      "          18       1.00      1.00      1.00        32\n",
      "          19       1.00      1.00      1.00        30\n",
      "          20       1.00      1.00      1.00        30\n",
      "          21       0.97      1.00      0.98        30\n",
      "          22       1.00      1.00      1.00        31\n",
      "          23       1.00      1.00      1.00        30\n",
      "          24       1.00      0.90      0.95        29\n",
      "          25       1.00      1.00      1.00        30\n",
      "          26       1.00      1.00      1.00        30\n",
      "\n",
      "    accuracy                           0.99       817\n",
      "   macro avg       0.99      0.99      0.99       817\n",
      "weighted avg       0.99      0.99      0.99       817\n",
      "\n",
      "Validation Accuracy: 0.9927\n"
     ]
    }
   ],
   "source": [
    "#Initialize the model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "#Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Validate the model\n",
    "y_val_pred = model.predict(X_val)\n",
    "print(\"Validation Set Metrics:\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "#Accuracy score for validation set\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b2843a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        30\n",
      "           1       1.00      1.00      1.00        31\n",
      "           2       0.97      1.00      0.98        29\n",
      "           3       0.97      1.00      0.98        30\n",
      "           4       1.00      1.00      1.00        33\n",
      "           5       1.00      1.00      1.00        29\n",
      "           6       0.97      0.97      0.97        30\n",
      "           7       1.00      1.00      1.00        30\n",
      "           8       0.97      0.97      0.97        30\n",
      "           9       1.00      1.00      1.00        29\n",
      "          10       1.00      0.93      0.97        30\n",
      "          11       1.00      0.97      0.98        30\n",
      "          12       1.00      1.00      1.00        30\n",
      "          13       1.00      1.00      1.00        30\n",
      "          14       0.97      1.00      0.98        29\n",
      "          15       1.00      1.00      1.00        33\n",
      "          16       1.00      0.97      0.98        29\n",
      "          17       1.00      1.00      1.00        29\n",
      "          18       1.00      1.00      1.00        33\n",
      "          19       1.00      1.00      1.00        31\n",
      "          20       1.00      1.00      1.00        30\n",
      "          21       0.94      1.00      0.97        29\n",
      "          22       1.00      1.00      1.00        32\n",
      "          23       1.00      0.97      0.98        31\n",
      "          24       0.97      0.97      0.97        29\n",
      "          25       0.97      1.00      0.98        31\n",
      "          26       1.00      1.00      1.00        31\n",
      "\n",
      "    accuracy                           0.99       818\n",
      "   macro avg       0.99      0.99      0.99       818\n",
      "weighted avg       0.99      0.99      0.99       818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = model.predict(X_test)\n",
    "print(\"Test Set Metrics:\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87bf7e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9890\n"
     ]
    }
   ],
   "source": [
    "# Accuracy score for test set\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5ce8b568",
   "metadata": {},
   "source": [
    "#Saving the model\n",
    "import pickle\n",
    "\n",
    "with open('chatbot_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "with open('tfidf_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2c0220",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
